# -*- coding: utf-8 -*-
"""progetto.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TY1C3oP5nXt67tdqQNYbJlOB36L2brRP

Import iniziali
"""

from google.colab import drive
drive.mount('/content/drive')
import keras
import matplotlib.pyplot as plt
import numpy as np
import skimage.io as io
import tensorflow as tf
from skimage.transform import resize
from tensorflow import convert_to_tensor

"""Caricamento del dataset:"""

batch_size = 32
img_width, img_height = 256, 256

from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1. / 255,zoom_range = 0.2,horizontal_flip = True, rotation_range=15)
train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/train',target_size=(img_width, img_height),batch_size=batch_size,class_mode='categorical')

val_datagen = ImageDataGenerator(rescale=1. / 255)
val_generator = val_datagen.flow_from_directory('/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/validation',target_size=(img_width, img_height),batch_size=batch_size,class_mode='categorical')

test_datagen = ImageDataGenerator(rescale=1. / 255)
test_generator = test_datagen.flow_from_directory('/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/test',target_size=(img_width, img_height),batch_size=8,class_mode='categorical')

"""Definizione della rete neruale implementata tramite la tecnica del fine tuning a partire dalla rete ResNet"""

def create_model():
  base_model = keras.applications.ResNet152V2(include_top=False, weights="imagenet", input_shape=(img_width, img_height, 3))#fine tuning
  
  for layer in base_model.layers:
    layer.trainable = False

  model = keras.models.Sequential()
  model.add(base_model)
  model.add(keras.layers.Flatten())
  model.add(keras.layers.Dense(2048, activation='relu'))
  model.add(keras.layers.Dense(512, activation='relu'))
  model.add(keras.layers.Dense(10, activation='softmax')) 

  model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=keras.optimizers.Adam() ,metrics=['accuracy'])

  return model

network= create_model()
network.summary()

network.fit_generator(train_generator, validation_data=val_generator, epochs=50,verbose=True)

"""Definiamo una lista ed un dictionary che ci consentano di passare da label a classi e viceversa"""

classes = ['Cane','Cavallo','Elefante','Farfalla', 'Gallina', 'Gatto', 'Mucca', 'Pecora', 'Ragno', 'Scoiattolo']

classes_dictionary = {
  'cane' : np.array([[1,0,0,0,0,0,0,0,0,0]]),
  'cavallo' : np.array([[0,1,0,0,0,0,0,0,0,0]]),
  'elefante' : np.array([[0,0,1,0,0,0,0,0,0,0]]),
  'farfalla' : np.array([[0,0,0,1,0,0,0,0,0,0]]),
  'gallina' : np.array([[0,0,0,0,1,0,0,0,0,0]]),
  'gatto' : np.array([[0,0,0,0,0,1,0,0,0,0]]),
  'mucca' : np.array([[0,0,0,0,0,0,1,0,0,0]]),
  'pecora' : np.array([[0,0,0,0,0,0,0,1,0,0]]),
  'ragno' : np.array([[0,0,0,0,0,0,0,0,1,0]]),
  'scoiattolo' : np.array([[0,0,0,0,0,0,0,0,0,1]])
}

network.load_weights("/content/drive/MyDrive/pesi_progetto_resnet")

network.save_weights("/content/drive/MyDrive/pesi_progetto_resnet")

imgs = next(test_generator)

predictions = network.predict(imgs[0])
p = np.argmax(predictions,1)
l = np.argmax(imgs[1],1)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(l, p)
print(cm)

accuracy = np.mean(p==l)
print(accuracy)

a = np.int64(p==l)
mistakes = list()
for i in range(len(a)):
  if(a[i]!= True):
    mistakes.append((imgs[0][i],predictions[i]))

for i in mistakes:
  plt.figure(figsize=(30,10))
  plt.title(classes[np.argmax(i[1])])
  plt.subplot(121);plt.imshow(i[0])
  plt.subplot(122);plt.bar(np.arange(10), i[1]); plt.xticks(np.arange(10), classes)

def non_targeted_attack(input_image, input_label, model,e=0.01, loss_function = tf.keras.losses.CategoricalCrossentropy()):

  input_image = convert_to_tensor(input_image)
  input_label = convert_to_tensor(input_label)

  with tf.GradientTape() as g:
    g.watch(input_image) 
    prediction = model(input_image) 
    loss = loss_function(input_label, prediction)
    
  gradient = g.gradient(loss, input_image)
  perturbation = e*np.sign(gradient.numpy())

  return perturbation

def targeted_attack(input_image, target_label, model,e, loss_function = tf.keras.losses.CategoricalCrossentropy()):
  input_image = convert_to_tensor(input_image)
  target_label = convert_to_tensor(target_label)

  with tf.GradientTape() as g:
    g.watch(input_image) #inizializzo per fare il gradiente
    prediction = model(input_image) 
    loss = loss_function(target_label, prediction)

  gradient = g.gradient(loss, input_image)#calcola il gradiente della loss rispetto all'ingresso x
  perturbation = -e*np.sign(gradient.numpy())
  return perturbation

def iterative_attack(attack, input_image, input_label, model, iterations, e, loss_function=tf.keras.losses.CategoricalCrossentropy()):
  fake_img = input_image.copy()
  for i in range(iterations):
    n = attack(fake_img, input_label, model, e, loss_function)
    fake_img += n
    fake_img = np.clip(fake_img, input_image-e, input_image+e)

  fake_img = np.clip(fake_img, 0, 1)
  return fake_img

orig_img = np.clip(x_true[0:1].copy(),0,1)
fake_img = iterative_attack(targeted_attack, orig_img, classes_dictionary['gatto'],network,10, 0.05)

pred = network.predict(orig_img)
fake_pred = network.predict(fake_img)

plt.figure(figsize=(30,10));plt.subplot(121); plt.imshow(orig_img[0]); plt.subplot(122); plt.bar(range(10), pred[0]); plt.xticks(np.arange(10), classes);
plt.figure(figsize=(30,10));plt.subplot(121); plt.imshow(fake_img[0]); plt.subplot(122); plt.bar(range(10), fake_pred[0]); plt.xticks(np.arange(10), classes);

diff = fake_img[0]-orig_img[0]

plt.figure(figsize=(15,5));plt.subplot(121); plt.imshow((diff-np.min(diff))/(np.max(diff)-np.min(diff))); plt.xlabel("Immagine differenza (a seguito di un enachment)")

print("Le due immagini differiscono di una quantit√† al massimo pari a: {}".format(np.max(np.abs(fake_img[0] - orig_img[0]))))

cane = io.imread("/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/test/cane/7.jpg")
scoiattolo = io.imread("/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/test/scoiattolo/6.jpg")
mucca = io.imread("/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/test/mucca/1.jpg")
farfalla = io.imread("/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/test/farfalla/6.jpg")
cavallo = io.imread("/content/drive/MyDrive/dataset.zip (Unzipped Files)/dataset/test/cavallo/1.jpg")

immagini = list()
immagini.append(cane)
immagini.append(scoiattolo)
immagini.append(mucca)
immagini.append(farfalla)
immagini.append(cavallo)

for i in immagini:
  i = resize(i, (img_width, img_height,3))
  plt.figure(); plt.imshow(i)

"""# Vecchio modello:"""

def create_model():
  model = keras.models.Sequential() 
  model.add(keras.layers.Conv2D(filters = 128, kernel_size=(5,5), padding='same', activation='relu', input_shape=(img_width, img_height, 3)))
  model.add(keras.layers.MaxPooling2D(2,2))
  model.add(keras.layers.Conv2D(filters = 128, kernel_size=(5,5), padding='same', activation='relu'))
  model.add(keras.layers.MaxPooling2D(2,2))
  model.add(keras.layers.Conv2D(filters = 256, kernel_size=(5,5), padding='same', activation='relu'))
  model.add(keras.layers.MaxPooling2D(2,2))
  model.add(keras.layers.Conv2D(filters = 256, kernel_size=(5,5), padding='same', activation='relu'))
  model.add(keras.layers.MaxPooling2D(2,2))
  model.add(keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same', activation='relu'))
  model.add(keras.layers.Flatten())
  model.add(keras.layers.Dense(2048, activation='relu'))
  model.add(keras.layers.Dense(512, activation='relu'))
  model.add(keras.layers.Dense(20, activation='softmax'))

  model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam() ,metrics=['accuracy'])

  return model

!pip install foolbox==3.3.1
from foolbox.models import TensorFlowModel
model_foolbox = TensorFlowModel(network, bounds=(0,1))
from foolbox.attacks import FGSM
attack = FGSM()

imgs = next(test_generator)

x_true = imgs[0]
y_true = imgs[1]
y_pred = network.predict(x_true)
acc = np.mean((np.argmax(y_true,-1)==np.argmax(y_pred,-1)))
print("Accuracy iniziale:")
print(acc)

from tensorflow import convert_to_tensor
preclip, x_advs, res = attack(
    model_foolbox,convert_to_tensor(x_true),
    convert_to_tensor(np.argmax(y_true,-1)), 
    epsilons=0.05)
x_advs = x_advs.numpy()

y_pred_adv = network.predict(x_advs)
acc = np.mean((np.argmax(y_pred_adv,-1)==np.argmax(y_true,-1)))
print("Accuracy dopo l'attacco")
print(acc)
print(res)